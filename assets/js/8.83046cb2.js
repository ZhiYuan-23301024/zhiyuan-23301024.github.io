(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{525:function(t,s,a){t.exports=a.p+"assets/img/25082301.74edfa32.png"},526:function(t,s,a){t.exports=a.p+"assets/img/25082302.b59b08b0.png"},527:function(t,s,a){t.exports=a.p+"assets/img/25082303.b8a16101.png"},528:function(t,s,a){t.exports=a.p+"assets/img/25082304.09648047.png"},529:function(t,s,a){t.exports=a.p+"assets/img/25082305.5a61a08f.png"},530:function(t,s,a){t.exports=a.p+"assets/img/25082306.177d27ff.png"},531:function(t,s,a){t.exports=a.p+"assets/img/25082307.3d82ebdd.png"},532:function(t,s,a){t.exports=a.p+"assets/img/file-20250828210948511.08bce8cb.png"},533:function(t,s,a){t.exports=a.p+"assets/img/file-20250828210949168.972fc3ac.png"},534:function(t,s,a){t.exports=a.p+"assets/img/file-20250828221002277.54a1034d.png"},535:function(t,s,a){t.exports=a.p+"assets/img/file-20250828221002829.b29adef8.png"},536:function(t,s,a){t.exports=a.p+"assets/img/file-20250828221007690.333c7ed5.png"},537:function(t,s,a){t.exports=a.p+"assets/img/file-20250828221008363.4c0f9c89.png"},538:function(t,s,a){t.exports=a.p+"assets/img/file-20250906121247960.bd511e9b.png"},539:function(t,s,a){t.exports=a.p+"assets/img/file-20250906130114923.c1ecc0f4.png"},540:function(t,s,a){t.exports=a.p+"assets/img/file-20250907130130085.3f13ff94.png"},597:function(t,s,a){"use strict";a.r(s);var n=a(2),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"_250815"}},[t._v("250815")]),t._v(" "),s("h3",{attrs:{id:"gnn相关"}},[t._v("GNN相关")]),t._v(" "),s("p",[s("img",{attrs:{src:a(525),alt:""}})]),t._v(" "),s("p",[t._v("点的特征变化由相邻点映射而来（参考全链接？）")]),t._v(" "),s("p",[t._v("这个过程输入图结构不变化")]),t._v(" "),s("p",[s("img",{attrs:{src:a(526),alt:""}})]),t._v(" "),s("p",[t._v("GNN只负责提取有用的特征，具体的分类和回归啥的还是要将数据降维到我们的传统CNN这块？")]),t._v(" "),s("p",[t._v("那么为什么不直接用传统的呢？传统的也可以提取特征")]),t._v(" "),s("p",[t._v("GNN相比之下的好处在于"),s("strong",[t._v("可以处理规模会变的数据")])]),t._v(" "),s("p",[t._v("社交网络啊啥的这种东西，每次处理的数据规模不一样")]),t._v(" "),s("p",[t._v("但是传统的cnn它是要resize的")]),t._v(" "),s("p",[s("img",{attrs:{src:a(527),alt:""}})]),t._v(" "),s("p",[s("img",{attrs:{src:a(528),alt:""}})]),t._v(" "),s("p",[s("img",{attrs:{src:a(529),alt:""}})]),t._v(" "),s("p",[s("img",{attrs:{src:a(530),alt:""}})]),t._v(" "),s("p",[s("img",{attrs:{src:a(531),alt:""}})]),t._v(" "),s("hr"),t._v(" "),s("p",[s("strong",[t._v("嵌入向量")])]),t._v(" "),s("p",[t._v("将本来的图元素依照其特征映射到一个"),s("strong",[t._v("低维连续向量")]),t._v("上，同时希望这个向量通过"),s("strong",[t._v("某种距离函数")]),t._v("能反映原图中的拓扑结构，比如关系远近？")]),t._v(" "),s("p",[s("strong",[t._v("提示和输出")])]),t._v(" "),s("ul",[s("li",[t._v("提示：图数据+任务目标")]),t._v(" "),s("li",[t._v("输出：根据任务不同而不同")])]),t._v(" "),s("p",[s("strong",[t._v("预训练和微调")])]),t._v(" "),s("ul",[s("li",[t._v("预训练：海量无标签数据，通用学习")]),t._v(" "),s("li",[t._v("微调：较少特定数据，针对学习")])]),t._v(" "),s("p",[t._v("无标签不意味着**“瞎几把乱学”**，而是标签是模型自己创造的而非人为标定")]),t._v(" "),s("h2",{attrs:{id:"xyy"}},[t._v("XYY")]),t._v(" "),s("ul",[s("li",[t._v("多任务提示结合")]),t._v(" "),s("li",[t._v("结合LLM的元路径提示")]),t._v(" "),s("li",[t._v("异构性试用版本")])]),t._v(" "),s("h2",{attrs:{id:"hal"}},[t._v("HAL")]),t._v(" "),s("ul",[s("li",[t._v("元路径怎么和HG融合？")]),t._v(" "),s("li",[t._v("冷启动——"),s("mark",[t._v("数据稀缺的情况下使用用户相似度进行推荐")])]),t._v(" "),s("li",[t._v("少样本")])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"如何缝合"}},[t._v("如何缝合")]),t._v(" "),s("ul",[s("li",[t._v("尽可能找到有价值的代码（"),s("strong",[t._v("可以直接拿来复用或改动代价小的")]),t._v("），比如两个项目里基于nn.module实现的子类，这些东西的ipo过程相对固定，没有什么所谓“自己的想法”，"),s("strong",[t._v("比较好缝合")]),t._v("，而针对某个数据集做的一些util或者说process属于个人特色比较鲜明的，不要去尝试缝合，会变得不幸")]),t._v(" "),s("li",[t._v("在搜集到了有价值的代码后，确定好缝合方向，再根据原论文的设计指导，利用有价值的代码碎块，搭建自己的GNN训练工作流。")])]),t._v(" "),s("h3",{attrs:{id:"hg高价值代码"}},[t._v("HG高价值代码")]),t._v(" "),s("h4",{attrs:{id:"conv"}},[t._v("conv")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("conv.myGATconv")]),t._v(":自定义的图注意力卷积层")])]),t._v(" "),s("h4",{attrs:{id:"gnn"}},[t._v("GNN")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("GNN.myGAT")]),t._v(":基于myGATconv搭建的异构图多层GAT模型")]),t._v(" "),s("li",[s("code",[t._v("GNN.GCN")]),t._v(":基于标准 GCN 层专门为异构图学习设计的神经网络模块。负责学习节点的表示，但分类头需要在模型外部定义")]),t._v(" "),s("li",[s("code",[t._v("GNN.GIN:")]),t._v("图同构网络模型，对照组")]),t._v(" "),s("li",[s("code",[t._v("GNN.GAT:")]),t._v("标准图注意力卷积层，对照组")])]),t._v(" "),s("h4",{attrs:{id:"hprompt"}},[t._v("hprompt")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("node_prompt_layer_feature_cat")]),t._v(":节点提示层，将可学习的提示向量拼接到每个节点的现有嵌入上")]),t._v(" "),s("li",[s("code",[t._v("node_prompt_layer_feature_cat_edge")]),t._v(":应用在边上")])]),t._v(" "),s("p",[t._v("上面那俩是同构图")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("hnode_prompt_layer_feature_cat_edge")])]),t._v(" "),s("li",[s("code",[t._v("hnode_prompt_layer_feature_cat")])])]),t._v(" "),s("p",[t._v("这俩是支持异构图")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("hprompt_gcn")]),t._v(":异构图卷积层")]),t._v(" "),s("li",[s("code",[t._v("hnode_prompt_layer_feature_sum")]),t._v(":异构图特征聚合层")])]),t._v(" "),s("h3",{attrs:{id:"gp高价值代码"}},[t._v("GP高价值代码")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("base_model")]),t._v(":基础模型，GraphPro的子类")]),t._v(" "),s("li",[s("code",[t._v("GraphPro")]),t._v(":处理时序图上推荐任务的图神经网络（GNN）模型。继承自 "),s("code",[t._v("BaseModel")]),t._v(" 基类")]),t._v(" "),s("li",[s("code",[t._v("finetune")]),t._v(":微调GraphPro脚本")]),t._v(" "),s("li",[s("code",[t._v("GraphProPlugin")]),t._v(":GraphPro作为插件的实现")]),t._v(" "),s("li",[s("code",[t._v("dynamicGNN")]),t._v("：动态 GNN")]),t._v(" "),s("li",[s("code",[t._v("graphprompt")]),t._v(" :提示 GNN")]),t._v(" "),s("li",[s("code",[t._v("LightGCN")]),t._v(" ：GraphPro的阉割版，作对照组用")])]),t._v(" "),s("h2",{attrs:{id:"缝合步骤"}},[t._v("缝合步骤")]),t._v(" "),s("ul",{staticClass:"contains-task-list"},[s("li",{staticClass:"task-list-item"},[s("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" 复现HGPROMPT")]),t._v(" "),s("li",{staticClass:"task-list-item"},[s("input",{staticClass:"task-list-item-checkbox",attrs:{checked:"",disabled:"",type:"checkbox"}}),t._v(" 复现GraphPro")]),t._v(" "),s("li",{staticClass:"task-list-item"},[s("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" 学习论文和pytorch（"),s("strong",[t._v("当前")]),t._v("）（1-2周）")]),t._v(" "),s("li",{staticClass:"task-list-item"},[s("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" 确定好缝合方向，出缝合后的算法流程图（1周）")]),t._v(" "),s("li",{staticClass:"task-list-item"},[s("input",{staticClass:"task-list-item-checkbox",attrs:{disabled:"",type:"checkbox"}}),t._v(" 代码级实现这个算法流程图（3-4周）")])]),t._v(" "),s("h2",{attrs:{id:"_250828-消融实验"}},[t._v("250828-消融实验")]),t._v(" "),s("p",[t._v("要复现以下几个部分并给出操作步骤")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("GraphPro")]),t._v(" 在不同数据集上与多种基线模型（采用不同骨干架构）的"),s("strong",[t._v("横向性能对比")]),t._v("，结果显示 "),s("strong",[t._v("GraphPro 持续展现出卓越的整体性能")]),t._v("。星号"),s("em",[t._v("标记表示相对于第二优性能的模型，在 p < 0.01 水平上具有")]),s("em",[t._v("统计学上的显著性")]),t._v(" "),s("img",{attrs:{src:a(532),alt:""}})]),t._v(" "),s("li",[t._v("微调阶段的关键组件消融研究。Y轴表示左侧的性能指标和右侧的收敛时期（显示为▽）。  "),s("img",{attrs:{src:a(533),alt:""}})]),t._v(" "),s("li",[t._v("通过考察四个变体来评估不同预训练模型架构如何影响微调结果，重点关注相对时间编码的使用和模型的内在表征强度。基线模型“LGN(+)TE”结合了时间编码 (TE) 和 LightGCN。“LGN(-)TE”变体在预训练期间排除 TE。另外两个变体“MixGCF(+)TE”和“SimGCL(+)TE”采用更强大的模型进行预训练，同时保持 LightGCN 用于微调。这些变体的预训练和微调之间的性能对比如图 4 所示。\n"),s("img",{attrs:{src:a(534),alt:""}})]),t._v(" "),s("li",[t._v("在亚马逊上，已调整和未调整用户的评估性能与最佳基线GPF的比较。\n"),s("img",{attrs:{src:a(535),alt:""}})]),t._v(" "),s("li",[t._v("展示了GraphPro和基线模型在淘宝和口碑上的训练曲线，散点标记了在不同阶段（预训练和微调）相对于epoch的性能。星形标记表示最终收敛，右侧y轴显示总耗时。\n"),s("img",{attrs:{src:a(536),alt:""}})]),t._v(" "),s("li",[t._v("为期5天的在线A/B测试结果。HPC：高度个性化内容。CC：点击次数。VCC：视频点击次数。\n（无法复现）\n"),s("img",{attrs:{src:a(537),alt:""}})])]),t._v(" "),s("h2",{attrs:{id:"_250903-如何制作数据集"}},[t._v("250903-如何制作数据集？")]),t._v(" "),s("h3",{attrs:{id:"原始数据集相关"}},[t._v("原始数据集相关")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"left"}},[t._v("数据集名称")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("主要特点")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("适用任务")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("获取方式/来源")]),t._v(" "),s("th")])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("OGB Amazon Products")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("包含亚马逊海量"),s("strong",[t._v("商品信息")]),t._v("和"),s("strong",[t._v("用户行为数据")]),t._v("，数据以图结构表示（节点可为商品、用户，边代表关联如相似性或交互）。是图机器学习领域的"),s("strong",[t._v("标准基准数据集")]),t._v("之一。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("节点分类")]),t._v("（如商品类别划分）、链接预测、推荐系统")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("a",{attrs:{href:"https://ogb.stanford.edu/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Open Graph Benchmark (OGB)"),s("OutboundLink")],1)]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("Mushroom Street (蘑菇街) Dataset")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("记录了蘑菇街平台上的"),s("strong",[t._v("顾客购物行为")]),t._v("和相关属性信息，包含用户基本信息、商品信息、购物行为、营销活动、用户评价等。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("用户行为分析、推荐系统、消费模式研究")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("a",{attrs:{href:"https://download.csdn.net/download/Pasby/90943354",target:"_blank",rel:"noopener noreferrer"}},[t._v("CSDN下载"),s("OutboundLink")],1)]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("E-commerce Clickstream & Transaction")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("包含7.5万条记录，详细记录了"),s("strong",[t._v("用户的会话信息")]),t._v("，如用户ID、会话ID、时间戳、事件类型、产品ID、交易金额以及目标事件等。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("点击流分析、序列模式挖掘、转化率分析、客户细分")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("未明确提供公开下载链接")]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("MovieLens")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("包含用户对电影的"),s("strong",[t._v("评分")]),t._v("、"),s("strong",[t._v("标签")]),t._v("和"),s("strong",[t._v("时间戳")]),t._v("，是推荐系统领域最为经典和常用的数据集之一。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("评分预测、Top-N推荐")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("a",{attrs:{href:"https://grouplens.org/datasets/movielens/",target:"_blank",rel:"noopener noreferrer"}},[t._v("MovieLens"),s("OutboundLink")],1)]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("Yelp Dataset")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("包含用户、商家、"),s("strong",[t._v("点评")]),t._v("、图片等多模态信息，适合研究基于商业评论的推荐。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("链接预测（用于推荐）、情感分析")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("a",{attrs:{href:"https://www.yelp.com/dataset",target:"_blank",rel:"noopener noreferrer"}},[t._v("Yelp Dataset"),s("OutboundLink")],1)]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("Tianchi 淘宝多模态检索数据集")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("提供淘宝搜索查询词和产品图像特征，"),s("strong",[t._v("未提供商品标题")]),t._v("。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("跨模态检索")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("a",{attrs:{href:"https://tianchi.aliyun.com/dataset/dataDetail?dataId=87809",target:"_blank",rel:"noopener noreferrer"}},[t._v("天池平台"),s("OutboundLink")],1)]),t._v(" "),s("td")]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("Watch and Buy 淘宝直播商品检索数据集")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("包含直播视频片段和对应讲解商品构成的匹配对，规模大、标注全、模态多。")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("物体检测、商品重识别、主播意图识别、多模态检索")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("a",{attrs:{href:"https://tianchi.aliyun.com/dataset/dataDetail?dataId=75730",target:"_blank",rel:"noopener noreferrer"}},[t._v("天池平台"),s("OutboundLink")],1)]),t._v(" "),s("td")])])]),t._v(" "),s("blockquote",[s("p",[t._v("[!note]")]),t._v(" "),s("p",[s("strong",[t._v("数据处理流程中的灵活性")]),t._v("​"),s("br"),t._v("\n在数据处理的"),s("strong",[t._v("中间步骤")]),t._v("，特别是数据"),s("strong",[t._v("预处理、清洗和格式转换")]),t._v("阶段，TXT 文件因其易于用常见命令行工具（如 "),s("code",[t._v("grep")]),t._v(", "),s("code",[t._v("sed")]),t._v(", "),s("code",[t._v("awk")]),t._v("）和脚本（Python 等）处理而备受青睐\n。许多"),s("strong",[t._v("历史悠久的经典图数据集")]),t._v("​（如某些社交网络、引文网络）最初就以 TXT 格式发布，为了保持一致性，后续研究常会沿用。\n若从高效的角度来考虑应该使用.pt和.npy文件")])]),t._v(" "),s("p",[t._v("参考文献"),s("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/603486955",target:"_blank",rel:"noopener noreferrer"}},[t._v("(79 封私信 / 80 条消息) 图神经网络（GNN）最简单全面原理与代码实现！ - 知乎"),s("OutboundLink")],1)]),t._v(" "),s("h3",{attrs:{id:"以淘宝用户数据集为例"}},[t._v("以淘宝用户数据集为例")]),t._v(" "),s("p",[t._v("数据来源 "),s("a",{attrs:{href:"https://blog.csdn.net/weixin_41574115/article/details/105440597",target:"_blank",rel:"noopener noreferrer"}},[t._v("数据分析—淘宝用户行为分析_用户历史交互商品-CSDN博客"),s("OutboundLink")],1)]),t._v(" "),s("h4",{attrs:{id:"_3-数据量"}},[t._v("3%数据量")]),t._v(" "),s("p",[t._v("本来想做完整的3个G的图数据预处理来着但是内存干爆了\n就采用了3%数据量\n"),s("img",{attrs:{src:a(538),alt:""}}),t._v("\n整个过程的目标是构建能够直接被pytorch反序列化的.pt用于存储边权和节点特征，而.npy文件用于存储节点id、边id到原始id的映射规则，也就是说，如果只需要训练并统计模型性能，那么理论上只需要.pt就行了\n这种结构的好处是可以直接调用，在项目里无需进行数据预处理了，换句话说这本身就是数据预处理")]),t._v(" "),s("p",[s("strong",[t._v("示范代码")])]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. ==================== 数据加载模块 ====================")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此处直接调用你处理好的数据集")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("load_processed_data")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'processed_data'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    加载处理好的图数据\n    此处调用了你预处理的数据集\n    """')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 加载图数据 [主要数据集调用]")]),t._v("\n    data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("data_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("/graph_data.pt'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 加载映射关系 [辅助数据调用]")]),t._v("\n    user_mapping "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("data_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("/user_mapping.npy'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_pickle"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    item_mapping "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("data_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("/item_mapping.npy'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow_pickle"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"数据集加载完成!"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"节点特征维度: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"边数量: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edge_index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" user_mapping"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" item_mapping\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. ==================== GNN模型定义 ====================")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UserItemGNN")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Module"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    用户-物品交互图神经网络模型\n    """')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" in_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hidden_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UserItemGNN"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GCNConv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("in_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hidden_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GCNConv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hidden_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropout "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dropout"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("forward")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge_index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge_weight"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 第一层图卷积")]),t._v("\n        x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge_index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge_weight"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropout"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 第二层图卷积")]),t._v("\n        x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge_index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge_weight"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" x\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. ==================== 训练函数 ====================")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("train_model")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    训练GNN模型\n    """')]),t._v("\n    model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    losses "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" epoch "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("epochs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zero_grad"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 前向传播 [使用数据集中的节点特征和边索引]")]),t._v("\n        out "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edge_index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edge_attr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里需要根据你的任务定义标签和损失函数")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 假设是节点分类任务，你需要有自己的标签数据")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# loss = criterion(out[data.train_mask], data.y[data.train_mask])")]),t._v("\n        \n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 由于你没有提供标签，这里使用一个伪损失函数示例")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 实际使用时需要替换为你的真实标签")]),t._v("\n        pseudo_loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.001")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这行需要替换")]),t._v("\n        \n        pseudo_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backward"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("step"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pseudo_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" epoch "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'Epoch ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("epoch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token format-spec"}},[t._v("03d")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", Loss: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("pseudo_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token format-spec"}},[t._v(".4f")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" losses\n\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5. ==================== 主函数 ====================")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置设备")]),t._v("\n    device "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cuda'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_available"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cpu'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"使用设备: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 加载数据 [主要数据集调用]")]),t._v("\n    data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" user_mapping"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" item_mapping "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" load_processed_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'processed_data'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建模型")]),t._v("\n    in_channels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 特征维度")]),t._v("\n    hidden_channels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),t._v("\n    out_channels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出维度，可根据任务调整")]),t._v("\n    \n    model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" UserItemGNN"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("in_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hidden_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out_channels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("device"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置优化器和损失函数")]),t._v("\n    optimizer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parameters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lr"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight_decay"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    criterion "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("CrossEntropyLoss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用于分类任务")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"开始训练模型..."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 训练模型 [使用数据集进行训练]")]),t._v("\n    losses "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" criterion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epochs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"开始评估模型..."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 评估模型 [使用数据集进行评估]")]),t._v("\n    outputs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" evaluate_model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 可视化训练过程")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Training Loss'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Epoch'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Loss'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Training Loss Over Time'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("savefig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_loss.png'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    plt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"模型训练和评估完成!"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"可以进一步进行:"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1. 节点表示学习（用于推荐）"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2. 链接预测（预测潜在交互）"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3. 用户/物品分类"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"__main__"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    main"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br"),s("span",{staticClass:"line-number"},[t._v("80")]),s("br"),s("span",{staticClass:"line-number"},[t._v("81")]),s("br"),s("span",{staticClass:"line-number"},[t._v("82")]),s("br"),s("span",{staticClass:"line-number"},[t._v("83")]),s("br"),s("span",{staticClass:"line-number"},[t._v("84")]),s("br"),s("span",{staticClass:"line-number"},[t._v("85")]),s("br"),s("span",{staticClass:"line-number"},[t._v("86")]),s("br"),s("span",{staticClass:"line-number"},[t._v("87")]),s("br"),s("span",{staticClass:"line-number"},[t._v("88")]),s("br"),s("span",{staticClass:"line-number"},[t._v("89")]),s("br"),s("span",{staticClass:"line-number"},[t._v("90")]),s("br"),s("span",{staticClass:"line-number"},[t._v("91")]),s("br"),s("span",{staticClass:"line-number"},[t._v("92")]),s("br"),s("span",{staticClass:"line-number"},[t._v("93")]),s("br"),s("span",{staticClass:"line-number"},[t._v("94")]),s("br"),s("span",{staticClass:"line-number"},[t._v("95")]),s("br"),s("span",{staticClass:"line-number"},[t._v("96")]),s("br"),s("span",{staticClass:"line-number"},[t._v("97")]),s("br"),s("span",{staticClass:"line-number"},[t._v("98")]),s("br"),s("span",{staticClass:"line-number"},[t._v("99")]),s("br"),s("span",{staticClass:"line-number"},[t._v("100")]),s("br"),s("span",{staticClass:"line-number"},[t._v("101")]),s("br"),s("span",{staticClass:"line-number"},[t._v("102")]),s("br"),s("span",{staticClass:"line-number"},[t._v("103")]),s("br"),s("span",{staticClass:"line-number"},[t._v("104")]),s("br"),s("span",{staticClass:"line-number"},[t._v("105")]),s("br"),s("span",{staticClass:"line-number"},[t._v("106")]),s("br"),s("span",{staticClass:"line-number"},[t._v("107")]),s("br"),s("span",{staticClass:"line-number"},[t._v("108")]),s("br"),s("span",{staticClass:"line-number"},[t._v("109")]),s("br"),s("span",{staticClass:"line-number"},[t._v("110")]),s("br"),s("span",{staticClass:"line-number"},[t._v("111")]),s("br"),s("span",{staticClass:"line-number"},[t._v("112")]),s("br"),s("span",{staticClass:"line-number"},[t._v("113")]),s("br"),s("span",{staticClass:"line-number"},[t._v("114")]),s("br"),s("span",{staticClass:"line-number"},[t._v("115")]),s("br"),s("span",{staticClass:"line-number"},[t._v("116")]),s("br"),s("span",{staticClass:"line-number"},[t._v("117")]),s("br"),s("span",{staticClass:"line-number"},[t._v("118")]),s("br"),s("span",{staticClass:"line-number"},[t._v("119")]),s("br"),s("span",{staticClass:"line-number"},[t._v("120")]),s("br"),s("span",{staticClass:"line-number"},[t._v("121")]),s("br"),s("span",{staticClass:"line-number"},[t._v("122")]),s("br")])]),s("h4",{attrs:{id:"_100-数据量"}},[t._v("100%数据量")]),t._v(" "),s("p",[t._v("如图，出现了内存爆炸\n"),s("img",{attrs:{src:a(539),alt:""}}),t._v("\n用pandas小批量读取解决")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("load_large_data")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""加载数据并显示进度条"""')]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取总行数（用于进度条）")]),t._v("\n\n    total_rows "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减去标题行")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 tqdm 包装 read_csv")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("total"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("total_rows"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" desc"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Loading CSV"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pbar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n        chunks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" chunk "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n                                usecols"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n                                header"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n                                names"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'user_id'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'item_id'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'behavior_type'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n                                chunksize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分块读取")]),t._v("\n\n            chunks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            pbar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 合并所有分块")]),t._v("\n\n    df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chunks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" df\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br")])]),s("p",[t._v("整个过程可以概括为："),s("strong",[t._v("将原始数据读入内存 → 在内存中构建图数据对象 → 将图数据对象序列化后保存到硬盘")]),t._v("。")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"left"}},[t._v("阶段")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("关键任务")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("内存使用特点")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("1. 原始数据读取")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("将磁盘上的原始数据（如CSV）加载到内存中的数据结构（如Pandas DataFrame）")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("内存占用高峰之一")]),t._v("，数据完全载入内存")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("2. 内存中数据处理")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("数据清洗、转换、构建图结构（节点、边、特征）、映射关系等")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("内存占用高峰之二")]),t._v("，原始数据与图结构同时存在")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[s("strong",[t._v("3. 序列化与保存")])]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("将内存中的图数据对象转换为字节流，写入硬盘上的特定格式文件（如"),s("code",[t._v(".pt")]),t._v("）")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("内存占用开始下降，数据从内存转移到磁盘")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}}),t._v(" "),s("td",{staticStyle:{"text-align":"left"}}),t._v(" "),s("td",{staticStyle:{"text-align":"left"}})])])]),t._v(" "),s("h4",{attrs:{id:"分块处理"}},[t._v("分块处理")]),t._v(" "),s("p",[s("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/446152634",target:"_blank",rel:"noopener noreferrer"}},[t._v("(80 封私信 / 80 条消息) 图分割Graph Partitioning技术总结 - 知乎"),s("OutboundLink")],1),t._v(" "),s("img",{attrs:{src:a(540),alt:""}}),t._v("\n将一个大图均匀的分成一系列的子图去适应分布式应用，每个子图存储在一台机器上，子图之间可以"),s("strong",[t._v("并行化执行")]),t._v("，如果当前子图需要其他子图的信息就需要"),s("strong",[t._v("通讯开销")]),t._v("，而图分割的质量影响着每台机器存储代价和机器之间通讯代价。")]),t._v(" "),s("p",[t._v("图分割的两个目标是负载均衡减少存储代价）和最小化切边或点(减少通讯代价），同时优化这两个目标是平衡图分割问题。")]),t._v(" "),s("h3",{attrs:{id:"_250920"}},[t._v("250920")]),t._v(" "),s("h3",{attrs:{id:"​实验配置总览​"}},[t._v("​实验配置总览​")]),t._v(" "),s("p",[t._v("所有实验的核心参数配置汇总，涵盖"),s("strong",[t._v("单图误差分析")]),t._v("、"),s("strong",[t._v("多图误差分析")]),t._v("及"),s("strong",[t._v("分布验证")]),t._v("三大类实验：")]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"​全局参数-所有实验共享-​​"}},[t._v("​"),s("strong",[t._v("全局参数（所有实验共享）​")]),t._v("​")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("​"),s("strong",[t._v("参数符号")]),t._v("​")]),t._v(" "),s("th",[t._v("​"),s("strong",[t._v("含义")]),t._v("​")]),t._v(" "),s("th",[t._v("​"),s("strong",[t._v("值")]),t._v("​")]),t._v(" "),s("th",[t._v("​"),s("strong",[t._v("依据")]),t._v("​")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("code",[t._v("FD")])]),t._v(" "),s("td",[t._v("特征维度")]),t._v(" "),s("td",[t._v("25")]),t._v(" "),s("td",[t._v("论文F=25（Theorem 5验证）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("NL")])]),t._v(" "),s("td",[t._v("GNN层数")]),t._v(" "),s("td",[t._v("3")]),t._v(" "),s("td",[t._v("默认3层（图3d验证）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("NE")])]),t._v(" "),s("td",[t._v("实验重复次数")]),t._v(" "),s("td",[t._v("30")]),t._v(" "),s("td",[t._v("附录C要求（确保统计显著性）")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("ALPHA")])]),t._v(" "),s("td",[t._v("LeakyReLU斜率")]),t._v(" "),s("td",[t._v("0.2")]),t._v(" "),s("td",[t._v("论文默认设置（Theorem 8依赖）")])])])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"​1-单图误差分析实验​"}},[t._v("​"),s("strong",[t._v("1. 单图误差分析实验")]),t._v("​")]),t._v(" "),s("h4",{attrs:{id:"​​-1-experiment-1-1-秩损失对误差上界的影响​"}},[t._v("​"),s("strong",[t._v("​(1) "),s("code",[t._v("experiment_1_1")]),t._v("：秩损失对误差上界的影响")]),t._v("​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 5")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("rank_to_reduce_list = [0, 1, 3, 5, 7, 10]  # 秩损失值（0=全秩）\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("非全秩矩阵的误差上界 ϵ≤ζ(θ)⋅κ(G)")])])]),t._v(" "),s("hr"),t._v(" "),s("h4",{attrs:{id:"​​-2-experiment-1-2-特征维度对误差的影响​"}},[t._v("​"),s("strong",[t._v("​(2) "),s("code",[t._v("experiment_1_2")]),t._v("：特征维度对误差的影响")]),t._v("​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 5")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("feature_dim_list = [15, 20, 25, 30, 35]  # 特征维度\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("特征维度 F与误差 ϵ的正相关性（κ(G)项）")])])]),t._v(" "),s("hr"),t._v(" "),s("h4",{attrs:{id:"​​-3-experiment-1-3-gnn层数对误差的影响​"}},[t._v("​"),s("strong",[t._v("​(3) "),s("code",[t._v("experiment_1_3")]),t._v("：GNN层数对误差的影响")]),t._v("​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 5")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("num_layer_list = [1, 2, 3, 4, 5]  # GNN层数\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("层数增加降低 ζ(θ)（提升模型表达能力）")])])]),t._v(" "),s("hr"),t._v(" "),s("h4",{attrs:{id:"​​-4-experiment-1-4-激活函数斜率的影响​"}},[t._v("​"),s("strong",[t._v("​(4) "),s("code",[t._v("experiment_1_4")]),t._v("：激活函数斜率的影响")]),t._v("​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 8")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("alpha_list = [0.05, 0.1, 0.2, 0.3]  # LeakyReLU负斜率\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("斜率 α对误差分布 χr​形态的影响")])])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"​2-多图误差分析实验​"}},[t._v("​"),s("strong",[t._v("2. 多图误差分析实验")]),t._v("​")]),t._v(" "),s("h4",{attrs:{id:"​​-1-experiment-3-1-单提示多图误差下界​"}},[t._v("​"),s("strong",[t._v("​(1) "),s("code",[t._v("experiment_3_1")]),t._v("：单提示多图误差下界")]),t._v("​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 6")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("num_graph_list = [5, 20, 35, 50]  # 图数量\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("单提示下误差下界 ϵ∘与图数量 M的关系")])])]),t._v(" "),s("hr"),t._v(" "),s("h4",{attrs:{id:"​​-2-experiment-3-2-多提示多图误差上界​"}},[t._v("​"),s("strong",[t._v("​(2) "),s("code",[t._v("experiment_3_2")]),t._v("：多提示多图误差上界")]),t._v("​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 7")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("num_graph_list = [30, 70, 110, 150]   # 图数量\nprompt_token_list = [5, 7, 9, 11]      # 提示token数量\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("误差上界 ϵ∗=∑i=k+1M​λi​/M​")])])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"​3-分布验证实验​"}},[t._v("​"),s("strong",[t._v("3. 分布验证实验")]),t._v("​")]),t._v(" "),s("h4",{attrs:{id:"​experiment-2-1-误差分布验证-​"}},[t._v("​"),s("code",[t._v("experiment_2_1")]),t._v("：误差分布验证**​")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("​"),s("strong",[t._v("目标定理")]),t._v("​：Theorem 8")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("关键参数")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("rank_to_reduce_list = [1, 3, 5]  # 秩损失值\nnum_samples = 100                # 样本量\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("验证内容")]),t._v("​：")]),t._v(" "),s("p",[t._v("误差 ϵ服从 χr​分布（r=秩损失值）")])])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"​实验配置统一原则​"}},[t._v("​"),s("strong",[t._v("实验配置统一原则")]),t._v("​")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("​"),s("strong",[t._v("模型初始化")]),t._v("​：")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("权重矩阵使用"),s("strong",[t._v("正交初始化")]),t._v("​（满足Theorem 3全秩条件）")])]),t._v(" "),s("li",[s("p",[t._v("下游任务头 C(⋅)随机初始化")])])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("数据操作设置")]),t._v("​：")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("图操作强度 β=0.7（70%概率删边/节点/改特征）")])]),t._v(" "),s("li",[s("p",[t._v("桥图 Gbri​通过求解 Fθ​(Gbri​)=C(Gori​)生成")])])])]),t._v(" "),s("li",[s("p",[t._v("​"),s("strong",[t._v("结果保存")]),t._v("​：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('# 文件名格式示例\nf"result/experiment_{实验编号}/{模型}_{提示类型}_{时间戳}_{参数名}.csv"\n')])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])])])]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"​关键参数关系图​"}},[t._v("​"),s("strong",[t._v("关键参数关系图")]),t._v("​")]),t._v(" "),s("div",{staticClass:"language-mermaid line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-mermaid"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("graph")]),t._v(" TD\n    A"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[全局参数]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" B"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[单图误差分析]")]),t._v("\n    A "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" C"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[多图误差分析]")]),t._v("\n    A "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" D"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[分布验证]")]),t._v("\n    B "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" B1"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[秩损失影响]")]),t._v("\n    B "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" B2"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[特征维度影响]")]),t._v("\n    B "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" B3"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[层数影响]")]),t._v("\n    B "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" B4"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[激活函数影响]")]),t._v("\n    C "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" C1"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[单提示多图]")]),t._v("\n    C "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" C2"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[多提示多图]")]),t._v("\n    D "),s("span",{pre:!0,attrs:{class:"token arrow operator"}},[t._v("--\x3e")]),t._v(" D1"),s("span",{pre:!0,attrs:{class:"token text string"}},[t._v("[χ²分布拟合]")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br")])]),s("p",[t._v("此配置体系完整覆盖论文第5章理论验证需求，所有参数均可在代码中直接调用"),s("code",[t._v("experiments_docker")]),t._v("模块执行。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" math\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" plotly"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_objects "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" go\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scipy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" stats\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" plotly"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" make_subplots\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tqdm "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" tqdm\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" taskers\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建实验记录目录")]),t._v("\nos"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"experiment_records"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("save_experiment_record")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("experiment_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    保存实验记录到CSV文件\n    :param experiment_type: 实验类型 (e.g., "single_graph", "distribution", "multi_graph")\n    :param params: 实验参数字典\n    :param results: 实验结果字典\n    """')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建唯一时间戳")]),t._v("\n    timestamp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strftime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%Y%m%d_%H%M%S"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建记录字典")]),t._v("\n    record "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"experiment_id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("experiment_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("_")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("timestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timestamp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" timestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"experiment_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" experiment_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 添加参数")]),t._v("\n    record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"param_')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 添加结果")]),t._v("\n    record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"result_')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建DataFrame")]),t._v("\n    df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存文件")]),t._v("\n    filename "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"experiment_records/')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("experiment_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('_records.csv"')])]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果文件存在则追加，否则创建新文件")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" os"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        existing_df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("existing_df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ignore_index"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"✅ 实验记录已保存至: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("save_results_to_csv")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    timestamp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("now"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strftime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%Y%m%d_%H%M%S"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    filename "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"result/distribution_analysis_')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("timestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('.csv"')])]),t._v("\n    data_to_save "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"variance"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"variance"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_to_save"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"Results saved to ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("experiment_1_docker")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trans_dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_4_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    losses "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 捕获所有参数")]),t._v("\n    params "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_layer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rank_to_reduce"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feature_dim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"trans_dense"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" trans_dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_4_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_4_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"model_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt_type\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    aug_list "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feature_dim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_layer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_rank"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"model_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"graph_size_lo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"graph_size_hi"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_to_loop"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"need_expect_value"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"max_epochs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"experiment_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"single_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hyper_para"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"link_dense"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"trans_dense"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" trans_dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_num"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"token_num"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inner_prune"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cross_prune"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cross_mat_num"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_4_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" desc"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Loop for different Upper LOSS"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" colour"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'blue'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" taskers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("multi_experiment_4_upper_bound"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    losses "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"loss_mean:')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", loss_var:")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("loss_var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\\n with para:[rank_to_reduce:")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(']"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存实验记录")]),t._v("\n    results "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"loss_mean"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"loss_variance"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" loss_var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_samples"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    save_experiment_record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"single_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_var\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("experiment_2_docker")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_samples"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 捕获所有参数")]),t._v("\n    params "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_samples"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_samples"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rank_to_reduce"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_layer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feature_dim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"model_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt_type\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 内部函数保持不变")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ... [保持原有代码不变] ...")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 实验执行部分")]),t._v("\n    num_repeats "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n    data_list "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_repeats"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" desc"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Repeating Experiments"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" colour"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"blue"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        data_curr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" tqdm"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_samples"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" desc"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Processing"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" colour"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            loss_curr "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" taskers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("container"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            data_curr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss_curr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_curr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mean_data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    var_data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    results "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mean_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"variance"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" var_data\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    save_results_to_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分布计算部分")]),t._v("\n    pdf_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pdf_std"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cdf_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cdf_std"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bins "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" calculate_distributions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_bins"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    bin_centers "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bins"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" bins"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n    all_data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("concatenate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    observed_freq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("histogram"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("all_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bins"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("bins"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    expected_freq "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stats"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pdf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bin_centers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("r"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" scale"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("all_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bins"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" bins"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("observed_freq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" expected_freq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    chi2_stat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" p_value "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stats"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("chisquare"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("observed_freq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" expected_freq"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存实验记录")]),t._v("\n    dist_results "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chi2_statistic"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" chi2_stat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"p_value"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" p_value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mean_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mean_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"variance"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" var_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pdf_mean"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pdf_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pdf_std"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pdf_std"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cdf_mean"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" cdf_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cdf_std"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" cdf_std"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_bins"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_bins\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    save_experiment_record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"distribution"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dist_results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" chi2_stat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" p_value\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("experiment_3_docker")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" need_ref"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trans_dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" num_4_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        para_prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prompt_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    losses "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 捕获所有参数")]),t._v("\n    params "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_layer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"rank_to_reduce"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feature_dim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"need_ref"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" need_ref"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"trans_dense"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" trans_dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_4_loss"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_4_loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"para_prompt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" para_prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"model_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt_type\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    aug_list "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feature_dim"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feature_dim"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_layer"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" num_layer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_rank"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"model_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" model_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" prompt_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"graph_size_lo"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"graph_size_hi"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_to_loop"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"need_expect_value"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" need_ref"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"max_epochs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"experiment_type"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"multi_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hyper_para"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"link_dense"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"trans_dense"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" trans_dense"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"prompt_num"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" para_prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"token_num"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" para_prompt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inner_prune"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cross_prune"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cross_mat_num"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" prompt_type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gpf"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" taskers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("multi_experiment_4_lower_bound"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" prompt_type "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'All-in-one'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'All-in-one-plus'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_to_loop"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"max_epochs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"max_epochs"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        loss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" taskers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("multi_experiment_4_quantile_bound"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("aug_list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    losses "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"loss_mean:')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", loss_var:")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("loss_var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\\n\\n with para:[rank_to_reduce:")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("rank_to_reduce"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(", num_graph:")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("num_graph"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v(']"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存实验记录")]),t._v("\n    results "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"loss_mean"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"loss_variance"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" loss_var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"num_samples"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("losses"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    save_experiment_record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"multi_graph"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" params"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" results"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" loss_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss_var\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"__main__"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br"),s("span",{staticClass:"line-number"},[t._v("52")]),s("br"),s("span",{staticClass:"line-number"},[t._v("53")]),s("br"),s("span",{staticClass:"line-number"},[t._v("54")]),s("br"),s("span",{staticClass:"line-number"},[t._v("55")]),s("br"),s("span",{staticClass:"line-number"},[t._v("56")]),s("br"),s("span",{staticClass:"line-number"},[t._v("57")]),s("br"),s("span",{staticClass:"line-number"},[t._v("58")]),s("br"),s("span",{staticClass:"line-number"},[t._v("59")]),s("br"),s("span",{staticClass:"line-number"},[t._v("60")]),s("br"),s("span",{staticClass:"line-number"},[t._v("61")]),s("br"),s("span",{staticClass:"line-number"},[t._v("62")]),s("br"),s("span",{staticClass:"line-number"},[t._v("63")]),s("br"),s("span",{staticClass:"line-number"},[t._v("64")]),s("br"),s("span",{staticClass:"line-number"},[t._v("65")]),s("br"),s("span",{staticClass:"line-number"},[t._v("66")]),s("br"),s("span",{staticClass:"line-number"},[t._v("67")]),s("br"),s("span",{staticClass:"line-number"},[t._v("68")]),s("br"),s("span",{staticClass:"line-number"},[t._v("69")]),s("br"),s("span",{staticClass:"line-number"},[t._v("70")]),s("br"),s("span",{staticClass:"line-number"},[t._v("71")]),s("br"),s("span",{staticClass:"line-number"},[t._v("72")]),s("br"),s("span",{staticClass:"line-number"},[t._v("73")]),s("br"),s("span",{staticClass:"line-number"},[t._v("74")]),s("br"),s("span",{staticClass:"line-number"},[t._v("75")]),s("br"),s("span",{staticClass:"line-number"},[t._v("76")]),s("br"),s("span",{staticClass:"line-number"},[t._v("77")]),s("br"),s("span",{staticClass:"line-number"},[t._v("78")]),s("br"),s("span",{staticClass:"line-number"},[t._v("79")]),s("br"),s("span",{staticClass:"line-number"},[t._v("80")]),s("br"),s("span",{staticClass:"line-number"},[t._v("81")]),s("br"),s("span",{staticClass:"line-number"},[t._v("82")]),s("br"),s("span",{staticClass:"line-number"},[t._v("83")]),s("br"),s("span",{staticClass:"line-number"},[t._v("84")]),s("br"),s("span",{staticClass:"line-number"},[t._v("85")]),s("br"),s("span",{staticClass:"line-number"},[t._v("86")]),s("br"),s("span",{staticClass:"line-number"},[t._v("87")]),s("br"),s("span",{staticClass:"line-number"},[t._v("88")]),s("br"),s("span",{staticClass:"line-number"},[t._v("89")]),s("br"),s("span",{staticClass:"line-number"},[t._v("90")]),s("br"),s("span",{staticClass:"line-number"},[t._v("91")]),s("br"),s("span",{staticClass:"line-number"},[t._v("92")]),s("br"),s("span",{staticClass:"line-number"},[t._v("93")]),s("br"),s("span",{staticClass:"line-number"},[t._v("94")]),s("br"),s("span",{staticClass:"line-number"},[t._v("95")]),s("br"),s("span",{staticClass:"line-number"},[t._v("96")]),s("br"),s("span",{staticClass:"line-number"},[t._v("97")]),s("br"),s("span",{staticClass:"line-number"},[t._v("98")]),s("br"),s("span",{staticClass:"line-number"},[t._v("99")]),s("br"),s("span",{staticClass:"line-number"},[t._v("100")]),s("br"),s("span",{staticClass:"line-number"},[t._v("101")]),s("br"),s("span",{staticClass:"line-number"},[t._v("102")]),s("br"),s("span",{staticClass:"line-number"},[t._v("103")]),s("br"),s("span",{staticClass:"line-number"},[t._v("104")]),s("br"),s("span",{staticClass:"line-number"},[t._v("105")]),s("br"),s("span",{staticClass:"line-number"},[t._v("106")]),s("br"),s("span",{staticClass:"line-number"},[t._v("107")]),s("br"),s("span",{staticClass:"line-number"},[t._v("108")]),s("br"),s("span",{staticClass:"line-number"},[t._v("109")]),s("br"),s("span",{staticClass:"line-number"},[t._v("110")]),s("br"),s("span",{staticClass:"line-number"},[t._v("111")]),s("br"),s("span",{staticClass:"line-number"},[t._v("112")]),s("br"),s("span",{staticClass:"line-number"},[t._v("113")]),s("br"),s("span",{staticClass:"line-number"},[t._v("114")]),s("br"),s("span",{staticClass:"line-number"},[t._v("115")]),s("br"),s("span",{staticClass:"line-number"},[t._v("116")]),s("br"),s("span",{staticClass:"line-number"},[t._v("117")]),s("br"),s("span",{staticClass:"line-number"},[t._v("118")]),s("br"),s("span",{staticClass:"line-number"},[t._v("119")]),s("br"),s("span",{staticClass:"line-number"},[t._v("120")]),s("br"),s("span",{staticClass:"line-number"},[t._v("121")]),s("br"),s("span",{staticClass:"line-number"},[t._v("122")]),s("br"),s("span",{staticClass:"line-number"},[t._v("123")]),s("br"),s("span",{staticClass:"line-number"},[t._v("124")]),s("br"),s("span",{staticClass:"line-number"},[t._v("125")]),s("br"),s("span",{staticClass:"line-number"},[t._v("126")]),s("br"),s("span",{staticClass:"line-number"},[t._v("127")]),s("br"),s("span",{staticClass:"line-number"},[t._v("128")]),s("br"),s("span",{staticClass:"line-number"},[t._v("129")]),s("br"),s("span",{staticClass:"line-number"},[t._v("130")]),s("br"),s("span",{staticClass:"line-number"},[t._v("131")]),s("br"),s("span",{staticClass:"line-number"},[t._v("132")]),s("br"),s("span",{staticClass:"line-number"},[t._v("133")]),s("br"),s("span",{staticClass:"line-number"},[t._v("134")]),s("br"),s("span",{staticClass:"line-number"},[t._v("135")]),s("br"),s("span",{staticClass:"line-number"},[t._v("136")]),s("br"),s("span",{staticClass:"line-number"},[t._v("137")]),s("br"),s("span",{staticClass:"line-number"},[t._v("138")]),s("br"),s("span",{staticClass:"line-number"},[t._v("139")]),s("br"),s("span",{staticClass:"line-number"},[t._v("140")]),s("br"),s("span",{staticClass:"line-number"},[t._v("141")]),s("br"),s("span",{staticClass:"line-number"},[t._v("142")]),s("br"),s("span",{staticClass:"line-number"},[t._v("143")]),s("br"),s("span",{staticClass:"line-number"},[t._v("144")]),s("br"),s("span",{staticClass:"line-number"},[t._v("145")]),s("br"),s("span",{staticClass:"line-number"},[t._v("146")]),s("br"),s("span",{staticClass:"line-number"},[t._v("147")]),s("br"),s("span",{staticClass:"line-number"},[t._v("148")]),s("br"),s("span",{staticClass:"line-number"},[t._v("149")]),s("br"),s("span",{staticClass:"line-number"},[t._v("150")]),s("br"),s("span",{staticClass:"line-number"},[t._v("151")]),s("br"),s("span",{staticClass:"line-number"},[t._v("152")]),s("br"),s("span",{staticClass:"line-number"},[t._v("153")]),s("br"),s("span",{staticClass:"line-number"},[t._v("154")]),s("br"),s("span",{staticClass:"line-number"},[t._v("155")]),s("br"),s("span",{staticClass:"line-number"},[t._v("156")]),s("br"),s("span",{staticClass:"line-number"},[t._v("157")]),s("br"),s("span",{staticClass:"line-number"},[t._v("158")]),s("br"),s("span",{staticClass:"line-number"},[t._v("159")]),s("br"),s("span",{staticClass:"line-number"},[t._v("160")]),s("br"),s("span",{staticClass:"line-number"},[t._v("161")]),s("br"),s("span",{staticClass:"line-number"},[t._v("162")]),s("br"),s("span",{staticClass:"line-number"},[t._v("163")]),s("br"),s("span",{staticClass:"line-number"},[t._v("164")]),s("br"),s("span",{staticClass:"line-number"},[t._v("165")]),s("br"),s("span",{staticClass:"line-number"},[t._v("166")]),s("br"),s("span",{staticClass:"line-number"},[t._v("167")]),s("br"),s("span",{staticClass:"line-number"},[t._v("168")]),s("br"),s("span",{staticClass:"line-number"},[t._v("169")]),s("br"),s("span",{staticClass:"line-number"},[t._v("170")]),s("br"),s("span",{staticClass:"line-number"},[t._v("171")]),s("br"),s("span",{staticClass:"line-number"},[t._v("172")]),s("br"),s("span",{staticClass:"line-number"},[t._v("173")]),s("br"),s("span",{staticClass:"line-number"},[t._v("174")]),s("br"),s("span",{staticClass:"line-number"},[t._v("175")]),s("br"),s("span",{staticClass:"line-number"},[t._v("176")]),s("br"),s("span",{staticClass:"line-number"},[t._v("177")]),s("br"),s("span",{staticClass:"line-number"},[t._v("178")]),s("br"),s("span",{staticClass:"line-number"},[t._v("179")]),s("br"),s("span",{staticClass:"line-number"},[t._v("180")]),s("br"),s("span",{staticClass:"line-number"},[t._v("181")]),s("br"),s("span",{staticClass:"line-number"},[t._v("182")]),s("br"),s("span",{staticClass:"line-number"},[t._v("183")]),s("br"),s("span",{staticClass:"line-number"},[t._v("184")]),s("br"),s("span",{staticClass:"line-number"},[t._v("185")]),s("br"),s("span",{staticClass:"line-number"},[t._v("186")]),s("br"),s("span",{staticClass:"line-number"},[t._v("187")]),s("br"),s("span",{staticClass:"line-number"},[t._v("188")]),s("br"),s("span",{staticClass:"line-number"},[t._v("189")]),s("br"),s("span",{staticClass:"line-number"},[t._v("190")]),s("br"),s("span",{staticClass:"line-number"},[t._v("191")]),s("br"),s("span",{staticClass:"line-number"},[t._v("192")]),s("br"),s("span",{staticClass:"line-number"},[t._v("193")]),s("br"),s("span",{staticClass:"line-number"},[t._v("194")]),s("br"),s("span",{staticClass:"line-number"},[t._v("195")]),s("br"),s("span",{staticClass:"line-number"},[t._v("196")]),s("br"),s("span",{staticClass:"line-number"},[t._v("197")]),s("br"),s("span",{staticClass:"line-number"},[t._v("198")]),s("br"),s("span",{staticClass:"line-number"},[t._v("199")]),s("br"),s("span",{staticClass:"line-number"},[t._v("200")]),s("br"),s("span",{staticClass:"line-number"},[t._v("201")]),s("br"),s("span",{staticClass:"line-number"},[t._v("202")]),s("br"),s("span",{staticClass:"line-number"},[t._v("203")]),s("br"),s("span",{staticClass:"line-number"},[t._v("204")]),s("br"),s("span",{staticClass:"line-number"},[t._v("205")]),s("br"),s("span",{staticClass:"line-number"},[t._v("206")]),s("br"),s("span",{staticClass:"line-number"},[t._v("207")]),s("br"),s("span",{staticClass:"line-number"},[t._v("208")]),s("br"),s("span",{staticClass:"line-number"},[t._v("209")]),s("br"),s("span",{staticClass:"line-number"},[t._v("210")]),s("br"),s("span",{staticClass:"line-number"},[t._v("211")]),s("br"),s("span",{staticClass:"line-number"},[t._v("212")]),s("br"),s("span",{staticClass:"line-number"},[t._v("213")]),s("br"),s("span",{staticClass:"line-number"},[t._v("214")]),s("br"),s("span",{staticClass:"line-number"},[t._v("215")]),s("br"),s("span",{staticClass:"line-number"},[t._v("216")]),s("br"),s("span",{staticClass:"line-number"},[t._v("217")]),s("br"),s("span",{staticClass:"line-number"},[t._v("218")]),s("br"),s("span",{staticClass:"line-number"},[t._v("219")]),s("br"),s("span",{staticClass:"line-number"},[t._v("220")]),s("br"),s("span",{staticClass:"line-number"},[t._v("221")]),s("br"),s("span",{staticClass:"line-number"},[t._v("222")]),s("br"),s("span",{staticClass:"line-number"},[t._v("223")]),s("br"),s("span",{staticClass:"line-number"},[t._v("224")]),s("br"),s("span",{staticClass:"line-number"},[t._v("225")]),s("br"),s("span",{staticClass:"line-number"},[t._v("226")]),s("br"),s("span",{staticClass:"line-number"},[t._v("227")]),s("br"),s("span",{staticClass:"line-number"},[t._v("228")]),s("br"),s("span",{staticClass:"line-number"},[t._v("229")]),s("br"),s("span",{staticClass:"line-number"},[t._v("230")]),s("br"),s("span",{staticClass:"line-number"},[t._v("231")]),s("br"),s("span",{staticClass:"line-number"},[t._v("232")]),s("br"),s("span",{staticClass:"line-number"},[t._v("233")]),s("br"),s("span",{staticClass:"line-number"},[t._v("234")]),s("br"),s("span",{staticClass:"line-number"},[t._v("235")]),s("br"),s("span",{staticClass:"line-number"},[t._v("236")]),s("br"),s("span",{staticClass:"line-number"},[t._v("237")]),s("br"),s("span",{staticClass:"line-number"},[t._v("238")]),s("br"),s("span",{staticClass:"line-number"},[t._v("239")]),s("br"),s("span",{staticClass:"line-number"},[t._v("240")]),s("br"),s("span",{staticClass:"line-number"},[t._v("241")]),s("br"),s("span",{staticClass:"line-number"},[t._v("242")]),s("br"),s("span",{staticClass:"line-number"},[t._v("243")]),s("br"),s("span",{staticClass:"line-number"},[t._v("244")]),s("br"),s("span",{staticClass:"line-number"},[t._v("245")]),s("br"),s("span",{staticClass:"line-number"},[t._v("246")]),s("br"),s("span",{staticClass:"line-number"},[t._v("247")]),s("br"),s("span",{staticClass:"line-number"},[t._v("248")]),s("br")])]),s("h3",{attrs:{id:"_250926"}},[t._v("250926")]),t._v(" "),s("p",[t._v("读码")]),t._v(" "),s("ul",[s("li",[s("mark",[t._v("gnn_models")]),t._v(":\n"),s("ul",[s("li",[t._v("GCN：核心特点在于通过奇异值分解（SVD）动态调整模型权重矩阵的秩（rank），用于控制模型复杂度\n"),s("ul",[s("li",[t._v("输入输出隐藏层维度控制一致，无偏置项")]),t._v(" "),s("li",[t._v("全局加和池化")]),t._v(" "),s("li",[s("mark",[t._v("存储**当前模型每一层权重矩阵的实际秩**")])])])]),t._v(" "),s("li",[t._v("GAT：与经典GAT区别同上，为每一层设定了一个目标秩 "),s("code",[t._v("tar_rank")]),t._v("，计算公式为 "),s("code",[t._v("input_dim - n_rank")]),t._v("。每一层的权重矩阵将输入特征投影到一个**维度降低了"),s("code",[t._v("n_rank")]),t._v("的子空间"),s("mark",[t._v("强制性的维度压缩或复杂度控制意图。")]),t._v("图。==")])])])]),t._v(" "),s("blockquote",[s("p",[t._v("总而言之，无论是GCN还是GAT，都是再模型的构建过程利用奇异值分解算法有意识地控制各个层权重矩阵的秩为特值，这是和经典GCN和GAT的最本质区别")])]),t._v(" "),s("ul",[s("li",[s("p",[t._v("graph_generation")]),t._v(" "),s("ul",[s("li",[t._v("generate_random_graph：生成随机图数据（节点特征维度、链接概率，节点数量上下限）")]),t._v(" "),s("li",[t._v("graph_generate")]),t._v(" "),s("li",[s("code",[t._v("'S'")]),t._v(": 生成"),s("strong",[t._v("完全随机合成")]),t._v("的图。")]),t._v(" "),s("li",[s("code",[t._v("'R'")]),t._v(": 从"),s("strong",[t._v("真实数据集")]),t._v("中加载图。")]),t._v(" "),s("li",[s("code",[t._v("'B'")]),t._v(": ​"),s("strong",[t._v("混合模式")]),t._v("，随机选择上述两种方式之一。")])])]),t._v(" "),s("li",[s("p",[t._v("graph_matching：")]),t._v(" "),s("ul",[s("li",[t._v("graph_matching：\n计算图转换和图提示结果之差，对差值计算L2范数，取均值")])])])]),t._v(" "),s("blockquote",[s("p",[s("strong",[t._v("作为核心的损失函数，直接衡量并引导优化“经过变换的图表示”与“添加了提示的图表示”之间的差异")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);